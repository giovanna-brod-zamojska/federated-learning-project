{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def running_in_colab():\n",
    "    return 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "\n",
    "branch = \"main\"\n",
    "username = \"giovanna-brod-zamojska\"\n",
    "repo = \"federated-learning-project\"\n",
    "\n",
    "is_private = True\n",
    "\n",
    "def clone_repo_if_needed(exists_ok: bool, username: str, repository: str, is_private: bool, branch: str = None):\n",
    "\n",
    "  colab_repo_path = f'/content/{repository}/'\n",
    "  \n",
    "  if running_in_colab():\n",
    "\n",
    "    if exists_ok and os.path.exists(colab_repo_path):\n",
    "        print(f\"Repository already exists at {colab_repo_path}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(colab_repo_path) or not exists_ok:\n",
    "\n",
    "        # Remove any existing repo\n",
    "        print(f\"Removing content of {colab_repo_path}\")\n",
    "        os.system(f\"rm -rf {colab_repo_path}\")\n",
    "        print(\"Current directory files and folders:\", os.system(\"ls\"))\n",
    "\n",
    "        print(\"Cloning GitHub repo...\")\n",
    "\n",
    "        if is_private:\n",
    "            # Clone private repository\n",
    "            # Clone the GitHub repo (only needed once, if not already cloned)\n",
    "            from getpass import getpass\n",
    "\n",
    "\n",
    "            # Prompt for GitHub token (ensure token has access to the repo)\n",
    "            token = getpass('Enter GitHub token: ')\n",
    "\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "            else: \n",
    "              !git clone https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "\n",
    "        else:\n",
    "            # Clone public repository\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://github.com/{username}/{repo}.git\n",
    "            else:\n",
    "              !git clone https://github.com/{username}/{repo}.git\n",
    "\n",
    "\n",
    "    requirements_path = f\"{colab_repo_path}/colab-requirements.txt\"\n",
    "    !pip install -r \"$requirements_path\"\n",
    "\n",
    "  else:\n",
    "    print(\"Not running in Google Colab. Skipping repository cloning.\")#\n",
    "\n",
    "\n",
    "\n",
    "def setup_notebook(repo_root_name: str = \"federated-learning-project\"):\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    if running_in_colab():\n",
    "        print(\"Sys.path: \", sys.path)\n",
    "\n",
    "        colab_repo_path = f'/content/{repo_root_name}/'\n",
    "         # Add the repository root to sys.path so modules can be imported\n",
    "        if str(colab_repo_path) not in sys.path:\n",
    "            sys.path.insert(0, colab_repo_path)\n",
    "            print(f\"Added {colab_repo_path} to sys.path\")\n",
    "    else:\n",
    "      \n",
    "        notebook_dir = Path().absolute()\n",
    "        project_root = notebook_dir.parent.parent\n",
    "\n",
    "        # Add project root to Python path if not already present\n",
    "        if str(project_root) not in sys.path:\n",
    "            sys.path.insert(0, str(project_root))\n",
    "            print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "        \n",
    "clone_repo_if_needed(branch=branch, exists_ok=True, username=username, repository=repo, is_private=is_private)\n",
    "\n",
    "setup_notebook()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from src.centralized_baseline.dataset import CIFAR100Dataset\n",
    "from src.centralized_baseline.experiment_manager import ExperimentManager\n",
    "from src.model_editing.centralized_baseline.trainer import ModelEditingTrainer\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "experiments_dir = \"./output\"\n",
    "\n",
    "if running_in_colab():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    experiments_dir = \"/content/drive/MyDrive/-\" # define your Google Drive path here\n",
    "    checkpoint_dir = experiments_dir + \"/checkpoints\"\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    print(f\"Setting random seed to {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def run_experiments(seed: int):\n",
    "\n",
    "        set_seed(seed)\n",
    "\n",
    "        exp = \"_EDIT_0\"\n",
    "\n",
    "        grid_dict = {\n",
    "            \"batch_size\": [128],\n",
    "            \"lr\": [0.01],\n",
    "            \"weight_decay\": [5e-4],\n",
    "            \"momentum\": [0.9],\n",
    "            \"epochs\": [20],\n",
    "            \"seed\": [seed],\n",
    "            \"num_workers\": [4],\n",
    "            \"accum_steps\": [1],\n",
    "            \"optimizer_type\": [\"SparseSGD\"],\n",
    "            \"augment\": [None],\n",
    "            \"sparsity\": [0.99, 0.95, 0.9], # model editing\n",
    "            \"rounds\": [1, 2, 3, 5, 10], # model editing\n",
    "            \"num_batches\": [None], # model editing\n",
    "            \"strategy\": [\"train_least_important\"], # model editing\n",
    "            \"approximate_fisher\": [True], # model editing\n",
    "        }\n",
    "\n",
    "        # Generate param grid from all combinations\n",
    "        keys, values = zip(*grid_dict.items())\n",
    "        param_grid = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "        manager = ExperimentManager(\n",
    "            param_grid=param_grid,\n",
    "            use_wandb=False,\n",
    "            project_name=\"federated-learning-project\", #wandb\n",
    "            group_name=\"centralized-baseline-model-editing\", #wandb\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "        )\n",
    "        _, _, results = manager.run(\n",
    "            trainer_class=ModelEditingTrainer,\n",
    "            dataset_class=CIFAR100Dataset,\n",
    "            run_name=\"baseline-model-editing\", #wandb\n",
    "            run_tags=[ f\"v{exp}\", \"baseline-model-editing\"], #wandb\n",
    "            resume_training_from_config=None,\n",
    "            model_editing=True,  # Enable model editing\n",
    "        )\n",
    "        print(\"Experiments completed.\\n\")\n",
    "\n",
    "        filename = f\"experiment_baseline_full_param_grid_search_v{exp}_MODEL_EDITING.json\"  \n",
    "        os.makedirs(experiments_dir, exist_ok=True)\n",
    "        file_path = os.path.join(experiments_dir, filename)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        print(f\"Results saved to {file_path}\")\n",
    "\n",
    "try:\n",
    "    run_experiments(seed=42)\n",
    "except:\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
