{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def running_in_colab():\n",
    "    return 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "\n",
    "branch = \"main\"\n",
    "username = \"giovanna-brod-zamojska\"\n",
    "repo = \"federated-learning-project\"\n",
    "\n",
    "is_private = True\n",
    "\n",
    "\n",
    "def clone_repo_if_needed(exists_ok: bool, username: str, repository: str, is_private: bool, branch: str = None):\n",
    "\n",
    "  colab_repo_path = f'/content/{repository}/'\n",
    "  \n",
    "  if running_in_colab():\n",
    "\n",
    "    if exists_ok and os.path.exists(colab_repo_path):\n",
    "        print(f\"Repository already exists at {colab_repo_path}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(colab_repo_path) or not exists_ok:\n",
    "\n",
    "        # Remove any existing repo\n",
    "        print(f\"Removing content of {colab_repo_path}\")\n",
    "        os.system(f\"rm -rf {colab_repo_path}\")\n",
    "        print(\"Current directory files and folders:\", os.system(\"ls\"))\n",
    "\n",
    "        print(\"Cloning GitHub repo...\")\n",
    "\n",
    "        if is_private:\n",
    "            # Clone private repository\n",
    "            # Clone the GitHub repo (only needed once, if not already cloned)\n",
    "            from getpass import getpass\n",
    "\n",
    "\n",
    "            # Prompt for GitHub token (ensure token has access to the repo)\n",
    "            token = getpass('Enter GitHub token: ')\n",
    "\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "            else: \n",
    "              !git clone https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "\n",
    "        else:\n",
    "            # Clone public repository\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://github.com/{username}/{repo}.git\n",
    "            else:\n",
    "              !git clone https://github.com/{username}/{repo}.git\n",
    "\n",
    "\n",
    "    requirements_path = f\"{colab_repo_path}/colab-requirements.txt\"\n",
    "    !pip install -r \"$requirements_path\"\n",
    "\n",
    "  else:\n",
    "    print(\"Not running in Google Colab. Skipping repository cloning.\")#\n",
    "\n",
    "\n",
    "\n",
    "def setup_notebook(repo_root_name: str = \"federated-learning-project\"):\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    if running_in_colab():\n",
    "        print(\"Sys.path: \", sys.path)\n",
    "\n",
    "        colab_repo_path = f'/content/{repo_root_name}/'\n",
    "         # Add the repository root to sys.path so modules can be imported\n",
    "        if str(colab_repo_path) not in sys.path:\n",
    "            sys.path.insert(0, colab_repo_path)\n",
    "            print(f\"Added {colab_repo_path} to sys.path\")\n",
    "    else:\n",
    "      \n",
    "        notebook_dir = Path().absolute()\n",
    "        project_root = notebook_dir.parent.parent\n",
    "\n",
    "        # Add project root to Python path if not already present\n",
    "        if str(project_root) not in sys.path:\n",
    "            sys.path.insert(0, str(project_root))\n",
    "            print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "        \n",
    "clone_repo_if_needed(branch=branch, exists_ok=True, username=username, repository=repo, is_private=is_private)\n",
    "\n",
    "setup_notebook()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from flwr.server import ServerApp\n",
    "from flwr.client import ClientApp\n",
    "from flwr.simulation import run_simulation\n",
    "\n",
    "from src.classes.fedavg import server_fn, client_fn\n",
    "from src.classes.trainer import Trainer as FederatedTrainer\n",
    "from src.classes.dataset import CIFAR100Dataset\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    print(f\"Setting random seed to {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed = 42 \n",
    "set_seed(seed)\n",
    "\n",
    "\n",
    "LOCAL_EPOCHS = 1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "NUM_CLIENTS = 100\n",
    "NC = 100\n",
    "NUM_ROUNDS = 2\n",
    "CLIENT_FRACTION_PER_ROUND = 0.1\n",
    "\n",
    "dataset = CIFAR100Dataset(num_clients=NUM_CLIENTS, nc=NC)\n",
    "\n",
    "trainer_config = {\n",
    "    \"seed\": seed,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"epochs\": LOCAL_EPOCHS,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "trainer = FederatedTrainer(\n",
    "    **trainer_config,\n",
    "    num_classes=dataset.get_num_labels(),\n",
    "    use_wandb=\"False\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "strategy_config = {\n",
    "    \"fraction_fit\": CLIENT_FRACTION_PER_ROUND,\n",
    "    \"fraction_eval\": CLIENT_FRACTION_PER_ROUND,\n",
    "}\n",
    "\n",
    "server_app = ServerApp(\n",
    "    server_fn=lambda ctx: server_fn(\n",
    "        ctx,\n",
    "        num_rounds=NUM_ROUNDS,\n",
    "        **strategy_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "client_app = ClientApp(\n",
    "    client_fn=lambda ctx: client_fn(\n",
    "        ctx,\n",
    "        dataset,\n",
    "        split_type=\"iid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Specify the resources each of your clients need\n",
    "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
    "\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
    "\n",
    "run_simulation(\n",
    "    client_app=client_app,\n",
    "    server_app=server_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
