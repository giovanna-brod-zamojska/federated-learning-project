{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def running_in_colab():\n",
    "    return 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "\n",
    "branch = \"giovanna/centralized-baseline\"\n",
    "username = \"giovanna-brod-zamojska\"\n",
    "repo = \"federated-learning-project\"\n",
    "\n",
    "is_private = True\n",
    "\n",
    "def clone_repo_if_needed(exists_ok: bool, username: str, repository: str, is_private: bool, branch: str = None):\n",
    "\n",
    "  colab_repo_path = f'/content/{repository}/'\n",
    "  \n",
    "  if running_in_colab():\n",
    "\n",
    "    if exists_ok and os.path.exists(colab_repo_path):\n",
    "        print(f\"Repository already exists at {colab_repo_path}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(colab_repo_path) or not exists_ok:\n",
    "\n",
    "        # Remove any existing repo\n",
    "        print(f\"Removing content of {colab_repo_path}\")\n",
    "        os.system(f\"rm -rf {colab_repo_path}\")\n",
    "        print(\"Current directory files and folders:\", os.system(\"ls\"))\n",
    "\n",
    "        print(\"Cloning GitHub repo...\")\n",
    "\n",
    "        if is_private:\n",
    "            # Clone private repository\n",
    "            # Clone the GitHub repo (only needed once, if not already cloned)\n",
    "            from getpass import getpass\n",
    "\n",
    "\n",
    "            # Prompt for GitHub token (ensure token has access to the repo)\n",
    "            token = getpass('Enter GitHub token: ')\n",
    "\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "            else: \n",
    "              !git clone https://{username}:{token}@github.com/{username}/{repo}.git\n",
    "\n",
    "        else:\n",
    "            # Clone public repository\n",
    "            if branch:\n",
    "              !git clone --branch {branch} https://github.com/{username}/{repo}.git\n",
    "            else:\n",
    "              !git clone https://github.com/{username}/{repo}.git\n",
    "\n",
    "\n",
    "    requirements_path = f\"{colab_repo_path}/colab-requirements.txt\"\n",
    "    !pip install -r \"$requirements_path\"\n",
    "\n",
    "  else:\n",
    "    print(\"Not running in Google Colab. Skipping repository cloning.\")#\n",
    "\n",
    "\n",
    "\n",
    "def setup_notebook(repo_root_name: str = \"federated-learning-project\"):\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    if running_in_colab():\n",
    "        print(\"Sys.path: \", sys.path)\n",
    "\n",
    "        colab_repo_path = f'/content/{repo_root_name}/'\n",
    "         # Add the repository root to sys.path so modules can be imported\n",
    "        if str(colab_repo_path) not in sys.path:\n",
    "            sys.path.insert(0, colab_repo_path)\n",
    "            print(f\"Added {colab_repo_path} to sys.path\")\n",
    "    else:\n",
    "      \n",
    "        notebook_dir = Path().absolute()\n",
    "        project_root = notebook_dir.parent.parent\n",
    "\n",
    "        # Add project root to Python path if not already present\n",
    "        if str(project_root) not in sys.path:\n",
    "            sys.path.insert(0, str(project_root))\n",
    "            print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "        \n",
    "clone_repo_if_needed(branch=branch, exists_ok=True, username=username, repository=repo, is_private=is_private)\n",
    "\n",
    "setup_notebook()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from src.centralized_baseline.trainer import Trainer as CentralizedBaselineTrainer\n",
    "from src.centralized_baseline.dataset import CIFAR100Dataset\n",
    "from src.centralized_baseline.experiment_manager import ExperimentManager\n",
    "from itertools import product\n",
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "experiments_dir = \"./output\"\n",
    "\n",
    "if running_in_colab():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    experiments_dir = \"/content/drive/MyDrive/polito2025/MLDL/Project/experiments\" # define your Google Drive path here\n",
    "    checkpoint_dir = experiments_dir + \"/checkpoints\"\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    print(f\"Setting random seed to {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def run_experiments(seed: int):\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    exp = \"14_test\"\n",
    "\n",
    "    # grid_dict = {\n",
    "    #     \"batch_size\": [128],\n",
    "    #     \"lr\": [0.1, 0.05, 0.01, 0.001],\n",
    "    #     \"weight_decay\": [5e-4],\n",
    "    #     \"momentum\": [0.9],\n",
    "    #     \"epochs\": [5, 10, 20],\n",
    "    #     \"seed\": [seed],\n",
    "    #     \"num_workers\": [4],\n",
    "    #     \"accum_steps\": [1],\n",
    "    #     \"optimizer_type\": [\"SGD\"],\n",
    "    #     \"augment\": [None]\n",
    "    # }\n",
    "    # best basline config:\n",
    "    grid_dict = {\n",
    "        \"batch_size\": [128],\n",
    "        \"lr\": [0.01],\n",
    "        \"weight_decay\": [5e-4],\n",
    "        \"momentum\": [0.9],\n",
    "        \"epochs\": [20],\n",
    "        \"seed\": [seed],\n",
    "        \"num_workers\": [4],\n",
    "        \"accum_steps\": [1],\n",
    "        \"optimizer_type\": [\"SGD\"],\n",
    "        \"augment\": [None]\n",
    "    }\n",
    "\n",
    "    # Generate param grid from all combinations\n",
    "    keys, values = zip(*grid_dict.items())\n",
    "    param_grid = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    manager = ExperimentManager(\n",
    "        param_grid=param_grid,\n",
    "        use_wandb=False,\n",
    "        project_name=\"federated-learning-project\", #wandb\n",
    "        group_name=\"centralized-baseline\", #wandb\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "    )\n",
    "    _, _, results = manager.run(\n",
    "        trainer_class=CentralizedBaselineTrainer,\n",
    "        dataset_class=CIFAR100Dataset,\n",
    "        run_name=\"baseline\", #wandb\n",
    "        run_tags=[\"full-training\", f\"v{exp}\"], #wandb\n",
    "        resume_training_from_config=None,\n",
    "        test=True # final test to run at end of the experiments using the best model\n",
    "    )\n",
    "    print(\"Experiments completed.\\n\")\n",
    "\n",
    "\n",
    "    # filename = f\"experiment_baseline_v{exp}_bs{bs}_lr{lr}_Tmax{Tmax}_ep{ep}_accum_steps{accum_steps}.json\"  \n",
    "    filename = f\"experiment_baseline_full_param_grid_search_v{exp}.json\"  \n",
    "    os.makedirs(experiments_dir, exist_ok=True)\n",
    "    file_path = os.path.join(experiments_dir, filename)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Results saved to {file_path}\")\n",
    "\n",
    "try:\n",
    "    run_experiments(seed=42)\n",
    "except:\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
